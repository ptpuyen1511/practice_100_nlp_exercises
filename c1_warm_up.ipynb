{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Đảo ngược xâu ký tự\n",
    "\n",
    "Hãy đảo ngược xâu ký tự \"stressed\" (theo thứ tự từ cuối xâu đến đầu xâu ký tự)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "s = 'stressed'\n",
    "\n",
    "print(s[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Trích xuất ký tự từ xâu ký tự\n",
    "Từ xâu ký tự \"MPyaktQrBoilk RCSahr\", hãy trích xuất các ký tự ở vị trí 2,4,6,8,10,12,14,16,18,20 và kết hợp theo thứ tự đó để tạo thành 1 xâu ký tự mới (ký tự space cũng được tính, các ký tự được đánh số từ 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patrol Car'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'MPyaktQrBoilk RCSahr'\n",
    "\n",
    "s = ''.join([c for i,c in enumerate(s) if i % 2 != 0])\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Kết hợp hai xâu ký tự\n",
    "Hãy kết hợp hai xâu ký tự \"Partrol\" và \"Car\" để tạo thành xâu mới \"PatrolCar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PartrolCar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Partrol'\n",
    "s2 = 'Car'\n",
    "\n",
    "s = s1 + s2\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Tokenize và thống kê số lượng ký tự của mỗi từ\n",
    "\n",
    "1. Tokenize câu sau: \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "2. Đưa ra danh sách gồm số ký tự alphabet trong mỗi từ theo thứ tự xuất hiện của từ đó trong câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Now',\n",
       " 'I',\n",
       " 'need',\n",
       " 'a',\n",
       " 'drink',\n",
       " 'alcoholic',\n",
       " 'of',\n",
       " 'course',\n",
       " 'after',\n",
       " 'the',\n",
       " 'heavy',\n",
       " 'lectures',\n",
       " 'involving',\n",
       " 'quantum',\n",
       " 'mechanics']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Tokenize\n",
    "import re\n",
    "\n",
    "s = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "list_tokens = re.split(r'[ ,.]', s)\n",
    "\n",
    "list_tokens = list(filter(lambda t: t != '', list_tokens))\n",
    "\n",
    "list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now --> {'N': 1, 'o': 1, 'w': 1}\n",
      "-------------------------------------------\n",
      "I --> {'I': 1}\n",
      "-------------------------------------------\n",
      "need --> {'n': 1, 'e': 2, 'd': 1}\n",
      "-------------------------------------------\n",
      "a --> {'a': 1}\n",
      "-------------------------------------------\n",
      "drink --> {'d': 1, 'r': 1, 'i': 1, 'n': 1, 'k': 1}\n",
      "-------------------------------------------\n",
      "alcoholic --> {'a': 1, 'l': 2, 'c': 2, 'o': 2, 'h': 1, 'i': 1}\n",
      "-------------------------------------------\n",
      "of --> {'o': 1, 'f': 1}\n",
      "-------------------------------------------\n",
      "course --> {'c': 1, 'o': 1, 'u': 1, 'r': 1, 's': 1, 'e': 1}\n",
      "-------------------------------------------\n",
      "after --> {'a': 1, 'f': 1, 't': 1, 'e': 1, 'r': 1}\n",
      "-------------------------------------------\n",
      "the --> {'t': 1, 'h': 1, 'e': 1}\n",
      "-------------------------------------------\n",
      "heavy --> {'h': 1, 'e': 1, 'a': 1, 'v': 1, 'y': 1}\n",
      "-------------------------------------------\n",
      "lectures --> {'l': 1, 'e': 2, 'c': 1, 't': 1, 'u': 1, 'r': 1, 's': 1}\n",
      "-------------------------------------------\n",
      "involving --> {'i': 2, 'n': 2, 'v': 2, 'o': 1, 'l': 1, 'g': 1}\n",
      "-------------------------------------------\n",
      "quantum --> {'q': 1, 'u': 2, 'a': 1, 'n': 1, 't': 1, 'm': 1}\n",
      "-------------------------------------------\n",
      "mechanics --> {'m': 1, 'e': 1, 'c': 2, 'h': 1, 'a': 1, 'n': 1, 'i': 1, 's': 1}\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "from collections import Counter\n",
    "\n",
    "for t in list_tokens:\n",
    "    t_count_char = dict(Counter(t))\n",
    "    print(t + ' --> ', end='')\n",
    "    print(t_count_char)\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Ký tự thành phần\n",
    "\n",
    "1. Tokenize câu sau: \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "2. Lấy ra ký tự đầu tiên của các từ ở vị trí 1, 5, 6, 7, 8, 9, 15, 16, 19; với các từ còn lại lấy ra 2 ký tự đầu tiên. Tạo ra một map từ các xâu ký tự được trích ra tới vị trí của từ trong câu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'He',\n",
       " 'Lied',\n",
       " 'Because',\n",
       " 'Boron',\n",
       " 'Could',\n",
       " 'Not',\n",
       " 'Oxidize',\n",
       " 'Fluorine',\n",
       " 'New',\n",
       " 'Nations',\n",
       " 'Might',\n",
       " 'Also',\n",
       " 'Sign',\n",
       " 'Peace',\n",
       " 'Security',\n",
       " 'Clause',\n",
       " 'Arthur',\n",
       " 'King',\n",
       " 'Can']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Tokenize\n",
    "\n",
    "s = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "list_tokens = re.split(r'[ ,.]', s)\n",
    "\n",
    "list_tokens = list(filter(lambda t: t != '', list_tokens))\n",
    "\n",
    "list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 1,\n",
       " 'He': 2,\n",
       " 'Li': 3,\n",
       " 'Be': 4,\n",
       " 'B': 5,\n",
       " 'C': 6,\n",
       " 'N': 7,\n",
       " 'O': 8,\n",
       " 'F': 9,\n",
       " 'Ne': 10,\n",
       " 'Na': 11,\n",
       " 'Mi': 12,\n",
       " 'Al': 13,\n",
       " 'Si': 14,\n",
       " 'P': 15,\n",
       " 'S': 16,\n",
       " 'Cl': 17,\n",
       " 'Ar': 18,\n",
       " 'K': 19,\n",
       " 'Ca': 20}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "idx_array = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "\n",
    "map_sub_s = {}\n",
    "\n",
    "for i,t in enumerate(list_tokens):\n",
    "    if (i + 1) in idx_array:\n",
    "        map_sub_s[t[0]] = i + 1\n",
    "    else:\n",
    "        map_sub_s[t[:2]] = i + 1\n",
    "        \n",
    "map_sub_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. n-gram\n",
    "\n",
    "1. Viết hàm sinh ra tất cả các n-gram từ một dãy cho trước (xâu ký tự hoặc danh sách).\n",
    "\n",
    "2. Sử dụng hàm đã viết, sinh ra word bi-gram và character bi-gram từ câu sau: \"I am an NLPer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def n_gram_generator(inputs, is_word_gram, n_gram):\n",
    "    '''\n",
    "    Generating n_gram for input string.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    inputs -- str or list\n",
    "    \n",
    "    is_wrod_gram -- bool\n",
    "        True - if want to generate word n_gram\n",
    "        False - whereas\n",
    "        \n",
    "    n_gram -- int\n",
    "        Number grams want to generate\n",
    "    \n",
    "    Returns:\n",
    "    ---------\n",
    "    All n_gram possible\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if isinstance(inputs, list):\n",
    "        for s in inputs:\n",
    "            result = []\n",
    "            \n",
    "            if is_word_gram == True:\n",
    "                list_tokens = re.split(r'[ ,.]', s)\n",
    "\n",
    "                list_tokens = list(filter(lambda t: t != '', list_tokens))\n",
    "\n",
    "                for i in range(len(list_tokens) - n_gram + 1):\n",
    "                    result.append(' '.join(list_tokens[i:i+n_gram]))\n",
    "\n",
    "            else:\n",
    "                for i in range(len(s) - n_gram + 1):\n",
    "                    result.append(s[i:i+n_gram])\n",
    "                    \n",
    "            results.append(result)\n",
    "                    \n",
    "    elif isinstance(inputs, str):\n",
    "        if is_word_gram == True:\n",
    "            list_tokens = re.split(r'[ ,.]', inputs)\n",
    "\n",
    "            list_tokens = list(filter(lambda t: t != '', list_tokens))\n",
    "\n",
    "            for i in range(len(list_tokens) - n_gram + 1):\n",
    "                results.append(' '.join(list_tokens[i:i+n_gram]))\n",
    "\n",
    "        else:\n",
    "            for i in range(len(inputs) - n_gram + 1):\n",
    "                results.append(inputs[i:i+n_gram])\n",
    "    else:\n",
    "        print('Input is not str or list!')\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word bi-gram: ['I am', 'am an', 'an NLPer']\n",
      "Character bi-gram: ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# Test input is str\n",
    "\n",
    "word_bigram = n_gram_generator(inputs=\"I am an NLPer\", is_word_gram=True, n_gram=2)\n",
    "char_bigram = n_gram_generator(inputs=\"I am an NLPer\", is_word_gram=False, n_gram=2)\n",
    "\n",
    "print('Word bi-gram: ' + str(word_bigram))\n",
    "print('Character bi-gram: ' + str(char_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ab', 'bc'], ['ce', 'ef']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test input is list\n",
    "n_gram_generator(inputs=['abc', 'cef'], is_word_gram=False, n_gram=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Tập hợp\n",
    "\n",
    "1. Sinh ra tập X và Y tương ứng là tập các character bi-gram từ hai xâu ký tự \"paraparaparadise\" và \"paragraph\".\n",
    "\n",
    "2. Sinh ra các tập hợp union, intersection và difference của X và Y\n",
    "\n",
    "3. Kiểm tra xem bi-gram 'se' có thuộc tập X (Y) hay không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se']\n",
      "['pa', 'ar', 'ra', 'ag', 'gr', 'ra', 'ap', 'ph']\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "X = n_gram_generator(inputs='paraparaparadise', is_word_gram=False, n_gram=2)\n",
    "Y = n_gram_generator(inputs='paragraph', is_word_gram=False, n_gram=2)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union --> {'ag', 'di', 'gr', 'is', 'ad', 'ar', 'ra', 'ap', 'pa', 'ph', 'se'}\n",
      "Intersection --> {'ar', 'ra', 'ap', 'pa'}\n",
      "Difference --> {'is', 'ad', 'se', 'di'}\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "X = set(X)\n",
    "Y = set(Y)\n",
    "\n",
    "union = X | Y         # X.union(Y)\n",
    "print('Union --> ' + str(union))\n",
    "\n",
    "intersection = X & Y  # X.intersection(Y)\n",
    "print('Intersection --> ' + str(intersection))\n",
    "\n",
    "difference = X - Y    # X.difference(Y)\n",
    "print('Difference --> ' + str(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'se' in X? --> True\n",
      "'se' in Y? --> False\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "print(\"'se' in X? --> \" + str('se' in X))\n",
    "print(\"'se' in Y? --> \" + str('se' in Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
