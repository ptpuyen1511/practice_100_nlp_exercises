{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương 8: Machine Learning\n",
    "Chương này yêu cầu bạn thực hiện bài toán sentiment analysis trên corpus sentence polarity dataset v1.0 trong Moview Review Data của tác giả Bo Pang và Lillian Lee. Yêu cầu của bài toán sentiment analysis là phân loại các câu thành positive và negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70. Download và tiền xử lý dữ liệu\n",
    "Sử dụng dữ liệu liên quan đến sentiment polarity của các câu (download tại đây), tạo dữ liệu chuẩn hoá (sentiment.txt) theo hướng dẫn dưới đây.\n",
    "\n",
    "1. Thêm vào '+1' ở bắt đầu các dòng trong file rt-polarity.pos (giữa +1 và nội dung của câu cách nhau bởi ký tự trắng).\n",
    "\n",
    "2. Thêm vào '-1' ở bắt đầu các dòng trong file rt-polarity.neg (giữa -1 và nội dung của câu cách nhau bởi ký tự trắng).\n",
    "\n",
    "3. Kết hợp nội dung thu được trong phần 1 và 2 để tạo thành file sentiment.txt\n",
    "\n",
    "Sau khi đã thu được file sentiment.txt, xác nhận số lượng các câu với positive polarity và các câu với negative polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open('rt-polaritydata/rt-polaritydata/rt-polarity.pos', 'r') as f:\n",
    "    pos = f.readlines()\n",
    "    \n",
    "with open('rt-polaritydata/rt-polaritydata/rt-polarity.neg', 'r') as f:\n",
    "    neg = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment.txt\n",
    "with open('sentiment.txt', 'w') as f:\n",
    "    for line in pos:\n",
    "        f.write('+1 ' + line)\n",
    "    \n",
    "    for line in neg:\n",
    "        f.write('-1 ' + line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n",
      "Pos sentence: +1 the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n",
      "Neg sentence: -1 enigma is well-made , but it's just too dry and too placid . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check sentiment.txt\n",
    "with open('sentiment.txt', 'r') as f:\n",
    "    sentiment_data = f.readlines()\n",
    "    \n",
    "print(len(sentiment_data))\n",
    "print('Pos sentence: ' + sentiment_data[0])\n",
    "print('Neg sentence: ' + sentiment_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 71. Stopwords\n",
    "Tạo ra danh sách các stopwords trong tiếng Anh. Sau đó viết 1 hàm để kiểm tra một từ có thuộc danh sách stopwords hay không. Hàm sẽ trả về giá trị TRUE nếu từ cho trước thuộc danh sách stopwords. Ngược lại hàm sẽ trả về giá trị FALSE. Sau đó viết mô tả về các test cho hàm đã viết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stopword(word):\n",
    "    \"\"\"\n",
    "    The function is used to check if a word is stopword\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Word that we want to check, e.g., ``he`` or ``eat``.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : bool\n",
    "        True if word in stopwords list.\n",
    "        False if word not in stopwords list.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> is_stopword('eat')\n",
    "    False\n",
    "    \n",
    "    >>> is_stopword('both')\n",
    "    True\n",
    "    \n",
    "    >>> is_stopword(1.5)\n",
    "    False\n",
    "    \n",
    "    >>> s = (2,2)\n",
    "    >>> is_stopword(s)\n",
    "    False\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return False if word is not str\n",
    "    if not isinstance(word, str):\n",
    "        return False\n",
    "    \n",
    "    stopwords = {\"both\", \"only\", \"wouldn\", \"against\", \"their\", \"now\", \"didn\", \"himself\", \"ma\", \"yours\", \"having\", \"me\", \"doesn\", \"needn\", \"most\", \"itself\", \"m\", \"s\", \"isn't\", \"shan\", \"did\", \"won't\", \"don\", \"mightn't\", \"where\", \"but\", \"when\", \"wasn't\", \"wouldn't\", \"who\", \"those\", \"more\", \"with\", \"and\", \"whom\", \"an\", \"into\", \"before\", \"you've\", \"it\", \"ve\", \"ain\", \"haven\", \"o\", \"some\", \"are\", \"doesn't\", \"few\", \"she\", \"then\", \"can\", \"will\", \"each\", \"myself\", \"than\", \"has\", \"they\", \"it's\", \"there\", \"hasn\", \"which\", \"until\", \"or\", \"out\", \"re\", \"on\", \"had\", \"your\", \"am\", \"have\", \"in\", \"under\", \"should\", \"been\", \"because\", \"ourselves\", \"shouldn't\", \"that\", \"too\", \"the\", \"from\", \"didn't\", \"you'll\", \"you\", \"haven't\", \"don't\", \"mustn\", \"hadn\", \"own\", \"during\", \"does\", \"his\", \"needn't\", \"by\", \"doing\", \"mustn't\", \"wasn\", \"ll\", \"theirs\", \"other\", \"you're\", \"if\", \"my\", \"over\", \"hasn't\", \"further\", \"above\", \"down\", \"again\", \"why\", \"how\", \"i\", \"its\", \"them\", \"weren't\", \"do\", \"themselves\", \"between\", \"through\", \"here\", \"weren\", \"this\", \"won\", \"isn\", \"all\", \"him\", \"while\", \"for\", \"yourselves\", \"were\", \"to\", \"you'd\", \"shouldn\", \"below\", \"very\", \"couldn\", \"about\", \"she's\", \"off\", \"her\", \"we\", \"d\", \"aren't\", \"just\", \"what\", \"yourself\", \"any\", \"shan't\", \"was\", \"be\", \"nor\", \"t\", \"y\", \"so\", \"hadn't\", \"a\", \"is\", \"couldn't\", \"that'll\", \"our\", \"after\", \"as\", \"he\", \"hers\", \"such\", \"once\", \"aren\", \"these\", \"herself\", \"of\", \"up\", \"same\", \"being\", \"mightn\", \"ours\", \"at\", \"not\", \"no\", \"should've\"}\n",
    "    \n",
    "    return word in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword('eat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword('both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = (2,2)\n",
    "is_stopword(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 72. Trích xuất đặc trưng\n",
    "Tự thiết kế các đặc trưng cho bài toán sentiment analysis. Sau đó trích xuất đặc trưng từ dữ liệu training.\n",
    "\n",
    "Hint: phương pháp trích xuất đặc trưng đơn giản nhất là sử dụng từ gốc (stem) các từ không trong danh sách các stopwords. Phương pháp này có thể sử dụng để làm hệ thống baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>becomes the last thing you would expect from a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with nary a glimmer of self-knowledge , [crane...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just another fish-out-of-water story that bare...</td>\n",
       "      <td>+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to say that this vapid vehicle is downright do...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nicely serves as an examination of a society i...</td>\n",
       "      <td>+1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment label\n",
       "0  becomes the last thing you would expect from a...    -1\n",
       "1  with nary a glimmer of self-knowledge , [crane...    -1\n",
       "2  just another fish-out-of-water story that bare...    +1\n",
       "3  to say that this vapid vehicle is downright do...    -1\n",
       "4  nicely serves as an examination of a society i...    +1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sentiment.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "random.shuffle(lines)\n",
    "    \n",
    "label = [s.split(' ', 1)[0] for s in lines]\n",
    "text = [s.strip().split(' ', 1)[1] for s in lines]\n",
    "\n",
    "data_df = pd.DataFrame(list(zip(text, label)), columns=['comment', 'label'])\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "data_df['simple_preprocessed_comment'] = [simple_preprocess(comment, deacc=True) for comment in data_df['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>simple_preprocessed_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>becomes the last thing you would expect from a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[becomes, the, last, thing, you, would, expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with nary a glimmer of self-knowledge , [crane...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[with, nary, glimmer, of, self, knowledge, cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just another fish-out-of-water story that bare...</td>\n",
       "      <td>+1</td>\n",
       "      <td>[just, another, fish, out, of, water, story, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to say that this vapid vehicle is downright do...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[to, say, that, this, vapid, vehicle, is, down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nicely serves as an examination of a society i...</td>\n",
       "      <td>+1</td>\n",
       "      <td>[nicely, serves, as, an, examination, of, soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment label  \\\n",
       "0  becomes the last thing you would expect from a...    -1   \n",
       "1  with nary a glimmer of self-knowledge , [crane...    -1   \n",
       "2  just another fish-out-of-water story that bare...    +1   \n",
       "3  to say that this vapid vehicle is downright do...    -1   \n",
       "4  nicely serves as an examination of a society i...    +1   \n",
       "\n",
       "                         simple_preprocessed_comment  \n",
       "0  [becomes, the, last, thing, you, would, expect...  \n",
       "1  [with, nary, glimmer, of, self, knowledge, cra...  \n",
       "2  [just, another, fish, out, of, water, story, t...  \n",
       "3  [to, say, that, this, vapid, vehicle, is, down...  \n",
       "4  [nicely, serves, as, an, examination, of, soci...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [becom, last, thing, would, expect, film, titl...\n",
       "1    [nari, glimmer, self, knowledg, crane, becom, ...\n",
       "2      [anoth, fish, water, stori, bare, stay, afloat]\n",
       "3    [say, vapid, vehicl, downright, doltish, unev,...\n",
       "4               [nice, serv, examin, societi, transit]\n",
       "Name: rmstopword_stemming_comment, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "poster = PorterStemmer()\n",
    "\n",
    "data_df['rmstopword_stemming_comment'] = [[poster.stem(word) for word in list_tokens if is_stopword(word) == False] for list_tokens in data_df['simple_preprocessed_comment']]\n",
    "\n",
    "data_df.head()['rmstopword_stemming_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
