{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương 8: Machine Learning\n",
    "Chương này yêu cầu bạn thực hiện bài toán sentiment analysis trên corpus sentence polarity dataset v1.0 trong Moview Review Data của tác giả Bo Pang và Lillian Lee. Yêu cầu của bài toán sentiment analysis là phân loại các câu thành positive và negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70. Download và tiền xử lý dữ liệu\n",
    "Sử dụng dữ liệu liên quan đến sentiment polarity của các câu (download tại đây), tạo dữ liệu chuẩn hoá (sentiment.txt) theo hướng dẫn dưới đây.\n",
    "\n",
    "1. Thêm vào '+1' ở bắt đầu các dòng trong file rt-polarity.pos (giữa +1 và nội dung của câu cách nhau bởi ký tự trắng).\n",
    "\n",
    "2. Thêm vào '-1' ở bắt đầu các dòng trong file rt-polarity.neg (giữa -1 và nội dung của câu cách nhau bởi ký tự trắng).\n",
    "\n",
    "3. Kết hợp nội dung thu được trong phần 1 và 2 để tạo thành file sentiment.txt\n",
    "\n",
    "Sau khi đã thu được file sentiment.txt, xác nhận số lượng các câu với positive polarity và các câu với negative polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open('rt-polaritydata/rt-polaritydata/rt-polarity.pos', 'r') as f:\n",
    "    pos = f.readlines()\n",
    "    \n",
    "with open('rt-polaritydata/rt-polaritydata/rt-polarity.neg', 'r') as f:\n",
    "    neg = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment.txt\n",
    "with open('sentiment.txt', 'w') as f:\n",
    "    for line in pos:\n",
    "        f.write('+1 ' + line)\n",
    "    \n",
    "    for line in neg:\n",
    "        f.write('-1 ' + line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n",
      "Pos sentence: +1 the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n",
      "Neg sentence: -1 enigma is well-made , but it's just too dry and too placid . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check sentiment.txt\n",
    "with open('sentiment.txt', 'r') as f:\n",
    "    sentiment_data = f.readlines()\n",
    "    \n",
    "print(len(sentiment_data))\n",
    "print('Pos sentence: ' + sentiment_data[0])\n",
    "print('Neg sentence: ' + sentiment_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 71. Stopwords\n",
    "Tạo ra danh sách các stopwords trong tiếng Anh. Sau đó viết 1 hàm để kiểm tra một từ có thuộc danh sách stopwords hay không. Hàm sẽ trả về giá trị TRUE nếu từ cho trước thuộc danh sách stopwords. Ngược lại hàm sẽ trả về giá trị FALSE. Sau đó viết mô tả về các test cho hàm đã viết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stopword(word):\n",
    "    \"\"\"\n",
    "    The function is used to check if a word is stopword\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Word that we want to check, e.g., ``he`` or ``eat``.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : bool\n",
    "        True if word in stopwords list.\n",
    "        False if word not in stopwords list.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> is_stopword('eat')\n",
    "    False\n",
    "    \n",
    "    >>> is_stopword('both')\n",
    "    True\n",
    "    \n",
    "    >>> is_stopword(1.5)\n",
    "    False\n",
    "    \n",
    "    >>> s = (2,2)\n",
    "    >>> is_stopword(s)\n",
    "    False\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return False if word is not str\n",
    "    if not isinstance(word, str):\n",
    "        return False\n",
    "    \n",
    "    stopwords = {\"both\", \"only\", \"wouldn\", \"against\", \"their\", \"now\", \"didn\", \"himself\", \"ma\", \"yours\", \"having\", \"me\", \"doesn\", \"needn\", \"most\", \"itself\", \"m\", \"s\", \"isn't\", \"shan\", \"did\", \"won't\", \"don\", \"mightn't\", \"where\", \"but\", \"when\", \"wasn't\", \"wouldn't\", \"who\", \"those\", \"more\", \"with\", \"and\", \"whom\", \"an\", \"into\", \"before\", \"you've\", \"it\", \"ve\", \"ain\", \"haven\", \"o\", \"some\", \"are\", \"doesn't\", \"few\", \"she\", \"then\", \"can\", \"will\", \"each\", \"myself\", \"than\", \"has\", \"they\", \"it's\", \"there\", \"hasn\", \"which\", \"until\", \"or\", \"out\", \"re\", \"on\", \"had\", \"your\", \"am\", \"have\", \"in\", \"under\", \"should\", \"been\", \"because\", \"ourselves\", \"shouldn't\", \"that\", \"too\", \"the\", \"from\", \"didn't\", \"you'll\", \"you\", \"haven't\", \"don't\", \"mustn\", \"hadn\", \"own\", \"during\", \"does\", \"his\", \"needn't\", \"by\", \"doing\", \"mustn't\", \"wasn\", \"ll\", \"theirs\", \"other\", \"you're\", \"if\", \"my\", \"over\", \"hasn't\", \"further\", \"above\", \"down\", \"again\", \"why\", \"how\", \"i\", \"its\", \"them\", \"weren't\", \"do\", \"themselves\", \"between\", \"through\", \"here\", \"weren\", \"this\", \"won\", \"isn\", \"all\", \"him\", \"while\", \"for\", \"yourselves\", \"were\", \"to\", \"you'd\", \"shouldn\", \"below\", \"very\", \"couldn\", \"about\", \"she's\", \"off\", \"her\", \"we\", \"d\", \"aren't\", \"just\", \"what\", \"yourself\", \"any\", \"shan't\", \"was\", \"be\", \"nor\", \"t\", \"y\", \"so\", \"hadn't\", \"a\", \"is\", \"couldn't\", \"that'll\", \"our\", \"after\", \"as\", \"he\", \"hers\", \"such\", \"once\", \"aren\", \"these\", \"herself\", \"of\", \"up\", \"same\", \"being\", \"mightn\", \"ours\", \"at\", \"not\", \"no\", \"should've\"}\n",
    "    \n",
    "    return word in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword('eat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword('both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = (2,2)\n",
    "is_stopword(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
