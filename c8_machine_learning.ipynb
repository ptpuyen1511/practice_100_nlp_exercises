{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"c8_machine_learning.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"AtPKIij3XldW","colab_type":"text"},"source":["# Chương 8: Machine Learning\n","Chương này yêu cầu bạn thực hiện bài toán sentiment analysis trên corpus sentence polarity dataset v1.0 trong Moview Review Data của tác giả Bo Pang và Lillian Lee. Yêu cầu của bài toán sentiment analysis là phân loại các câu thành positive và negative sentiments."]},{"cell_type":"markdown","metadata":{"id":"py7ELby0XldX","colab_type":"text"},"source":["# 70. Download và tiền xử lý dữ liệu\n","Sử dụng dữ liệu liên quan đến sentiment polarity của các câu (download tại đây), tạo dữ liệu chuẩn hoá (sentiment.txt) theo hướng dẫn dưới đây.\n","\n","1. Thêm vào '+1' ở bắt đầu các dòng trong file rt-polarity.pos (giữa +1 và nội dung của câu cách nhau bởi ký tự trắng).\n","\n","2. Thêm vào '-1' ở bắt đầu các dòng trong file rt-polarity.neg (giữa -1 và nội dung của câu cách nhau bởi ký tự trắng).\n","\n","3. Kết hợp nội dung thu được trong phần 1 và 2 để tạo thành file sentiment.txt\n","\n","Sau khi đã thu được file sentiment.txt, xác nhận số lượng các câu với positive polarity và các câu với negative polarity."]},{"cell_type":"code","metadata":{"id":"mhBAJMJcXldY","colab_type":"code","colab":{}},"source":["# Read files\n","with open('rt-polaritydata/rt-polaritydata/rt-polarity.pos', 'r', encoding='latin-1') as f:\n","    pos = f.readlines()\n","    \n","with open('rt-polaritydata/rt-polaritydata/rt-polarity.neg', 'r', encoding='latin-1') as f:\n","    neg = f.readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yw8-Q5XHXldd","colab_type":"code","colab":{}},"source":["# Create sentiment.txt\n","with open('sentiment.txt', 'w') as f:\n","    for line in pos:\n","        f.write('+1 ' + line)\n","    \n","    for line in neg:\n","        f.write('-1 ' + line)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AO3ED-ZzXldi","colab_type":"code","outputId":"9050d568-9131-4f44-ab10-ddbfe6c2d41f","executionInfo":{"status":"ok","timestamp":1586443101957,"user_tz":-420,"elapsed":605,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Check sentiment.txt\n","with open('sentiment.txt', 'r') as f:\n","    sentiment_data = f.readlines()\n","    \n","print(len(sentiment_data))\n","print('Pos sentence: ' + sentiment_data[0])\n","print('Neg sentence: ' + sentiment_data[-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10662\n","Pos sentence: +1 the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n","\n","Neg sentence: -1 enigma is well-made , but it's just too dry and too placid . \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5yLIEN6qXldp","colab_type":"text"},"source":["# 71. Stopwords\n","Tạo ra danh sách các stopwords trong tiếng Anh. Sau đó viết 1 hàm để kiểm tra một từ có thuộc danh sách stopwords hay không. Hàm sẽ trả về giá trị TRUE nếu từ cho trước thuộc danh sách stopwords. Ngược lại hàm sẽ trả về giá trị FALSE. Sau đó viết mô tả về các test cho hàm đã viết."]},{"cell_type":"code","metadata":{"id":"_o9S45DSXldp","colab_type":"code","colab":{}},"source":["def is_stopword(word):\n","    \"\"\"\n","    The function is used to check if a word is stopword\n","    \n","    Parameters\n","    ----------\n","    word : str\n","        Word that we want to check, e.g., ``he`` or ``eat``.\n","    \n","    Returns\n","    -------\n","    out : bool\n","        True if word in stopwords list.\n","        False if word not in stopwords list.\n","        \n","    Examples\n","    --------\n","    >>> is_stopword('eat')\n","    False\n","    \n","    >>> is_stopword('both')\n","    True\n","    \n","    >>> is_stopword(1.5)\n","    False\n","    \n","    >>> s = (2,2)\n","    >>> is_stopword(s)\n","    False\n","    \"\"\"\n","    \n","    # Return False if word is not str\n","    if not isinstance(word, str):\n","        return False\n","    \n","    stopwords = {\"both\", \"only\", \"wouldn\", \"against\", \"their\", \"now\", \"didn\", \"himself\", \"ma\", \"yours\", \"having\", \"me\", \"doesn\", \"needn\", \"most\", \"itself\", \"m\", \"s\", \"isn't\", \"shan\", \"did\", \"won't\", \"don\", \"mightn't\", \"where\", \"but\", \"when\", \"wasn't\", \"wouldn't\", \"who\", \"those\", \"more\", \"with\", \"and\", \"whom\", \"an\", \"into\", \"before\", \"you've\", \"it\", \"ve\", \"ain\", \"haven\", \"o\", \"some\", \"are\", \"doesn't\", \"few\", \"she\", \"then\", \"can\", \"will\", \"each\", \"myself\", \"than\", \"has\", \"they\", \"it's\", \"there\", \"hasn\", \"which\", \"until\", \"or\", \"out\", \"re\", \"on\", \"had\", \"your\", \"am\", \"have\", \"in\", \"under\", \"should\", \"been\", \"because\", \"ourselves\", \"shouldn't\", \"that\", \"too\", \"the\", \"from\", \"didn't\", \"you'll\", \"you\", \"haven't\", \"don't\", \"mustn\", \"hadn\", \"own\", \"during\", \"does\", \"his\", \"needn't\", \"by\", \"doing\", \"mustn't\", \"wasn\", \"ll\", \"theirs\", \"other\", \"you're\", \"if\", \"my\", \"over\", \"hasn't\", \"further\", \"above\", \"down\", \"again\", \"why\", \"how\", \"i\", \"its\", \"them\", \"weren't\", \"do\", \"themselves\", \"between\", \"through\", \"here\", \"weren\", \"this\", \"won\", \"isn\", \"all\", \"him\", \"while\", \"for\", \"yourselves\", \"were\", \"to\", \"you'd\", \"shouldn\", \"below\", \"very\", \"couldn\", \"about\", \"she's\", \"off\", \"her\", \"we\", \"d\", \"aren't\", \"just\", \"what\", \"yourself\", \"any\", \"shan't\", \"was\", \"be\", \"nor\", \"t\", \"y\", \"so\", \"hadn't\", \"a\", \"is\", \"couldn't\", \"that'll\", \"our\", \"after\", \"as\", \"he\", \"hers\", \"such\", \"once\", \"aren\", \"these\", \"herself\", \"of\", \"up\", \"same\", \"being\", \"mightn\", \"ours\", \"at\", \"not\", \"no\", \"should've\"}\n","    \n","    return word in stopwords"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYE29zD2Xlds","colab_type":"code","outputId":"d46f1e69-07e2-41ae-ebda-b8a13cd0a72c","executionInfo":{"status":"ok","timestamp":1586443104424,"user_tz":-420,"elapsed":1029,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["is_stopword('eat')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"tg-De2ISXldv","colab_type":"code","outputId":"5c176386-8133-4599-8cca-7ddf9b7c9549","executionInfo":{"status":"ok","timestamp":1586443104425,"user_tz":-420,"elapsed":607,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["is_stopword('both')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Lugo0AL5Xldz","colab_type":"code","outputId":"d65bfa4b-2d98-4d47-a438-255d9a9ce0e2","executionInfo":{"status":"ok","timestamp":1586443105316,"user_tz":-420,"elapsed":825,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["is_stopword(1.5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Odt1Kva9Xld4","colab_type":"code","outputId":"5b4b8427-30f4-4429-a1b2-c0e551a3d872","executionInfo":{"status":"ok","timestamp":1586443106004,"user_tz":-420,"elapsed":772,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["s = (2,2)\n","is_stopword(s)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"9YlzYhIAXld9","colab_type":"text"},"source":["# 72. Trích xuất đặc trưng\n","Tự thiết kế các đặc trưng cho bài toán sentiment analysis. Sau đó trích xuất đặc trưng từ dữ liệu training.\n","\n","Hint: phương pháp trích xuất đặc trưng đơn giản nhất là sử dụng từ gốc (stem) các từ không trong danh sách các stopwords. Phương pháp này có thể sử dụng để làm hệ thống baseline."]},{"cell_type":"markdown","metadata":{"id":"ahQlgQtZXld9","colab_type":"text"},"source":["## Read data"]},{"cell_type":"code","metadata":{"id":"WuE6LRI5Xld-","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrEiHmFQXleA","colab_type":"code","outputId":"482b760e-93ab-4097-f057-4d428de922f7","executionInfo":{"status":"ok","timestamp":1586443109254,"user_tz":-420,"elapsed":1067,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["with open('sentiment.txt', 'r') as f:\n","    lines = f.readlines()\n","    \n","random.shuffle(lines)\n","    \n","label = [1 if s.split(' ', 1)[0] == '+1' else 0 for s in lines]\n","text = [s.strip().split(' ', 1)[1] for s in lines]\n","\n","data_df = pd.DataFrame(list(zip(text, label)), columns=['comment', 'label'])\n","\n","data_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>it's absolutely amazing how first-time directo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>if you like quirky , odd movies and/or the iro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the modern-day characters are nowhere near as ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>a metaphor for a modern-day urban china search...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a photographic marvel of sorts , and it's cert...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  label\n","0  it's absolutely amazing how first-time directo...      0\n","1  if you like quirky , odd movies and/or the iro...      1\n","2  the modern-day characters are nowhere near as ...      0\n","3  a metaphor for a modern-day urban china search...      1\n","4  a photographic marvel of sorts , and it's cert...      1"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"Uln73RmjXleQ","colab_type":"text"},"source":["## Simple preprocess"]},{"cell_type":"code","metadata":{"id":"0qEZZMwrXleR","colab_type":"code","colab":{}},"source":["from gensim.utils import simple_preprocess\n","\n","data_df['simple_preprocessed_comment'] = [simple_preprocess(comment, deacc=True) for comment in data_df['comment']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcRieVJtXleW","colab_type":"code","outputId":"aaadbd69-0de7-4d55-a394-d588a9318e99","executionInfo":{"status":"ok","timestamp":1586443111940,"user_tz":-420,"elapsed":619,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>label</th>\n","      <th>simple_preprocessed_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>it's absolutely amazing how first-time directo...</td>\n","      <td>0</td>\n","      <td>[it, absolutely, amazing, how, first, time, di...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>if you like quirky , odd movies and/or the iro...</td>\n","      <td>1</td>\n","      <td>[if, you, like, quirky, odd, movies, and, or, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the modern-day characters are nowhere near as ...</td>\n","      <td>0</td>\n","      <td>[the, modern, day, characters, are, nowhere, n...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>a metaphor for a modern-day urban china search...</td>\n","      <td>1</td>\n","      <td>[metaphor, for, modern, day, urban, china, sea...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a photographic marvel of sorts , and it's cert...</td>\n","      <td>1</td>\n","      <td>[photographic, marvel, of, sorts, and, it, cer...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  ...                        simple_preprocessed_comment\n","0  it's absolutely amazing how first-time directo...  ...  [it, absolutely, amazing, how, first, time, di...\n","1  if you like quirky , odd movies and/or the iro...  ...  [if, you, like, quirky, odd, movies, and, or, ...\n","2  the modern-day characters are nowhere near as ...  ...  [the, modern, day, characters, are, nowhere, n...\n","3  a metaphor for a modern-day urban china search...  ...  [metaphor, for, modern, day, urban, china, sea...\n","4  a photographic marvel of sorts , and it's cert...  ...  [photographic, marvel, of, sorts, and, it, cer...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"U3YZICXqXleZ","colab_type":"text"},"source":["## Remove stopword"]},{"cell_type":"code","metadata":{"id":"aHwYS12rXlea","colab_type":"code","outputId":"a7d804aa-318f-46f9-8613-ac1cc24e4d0c","executionInfo":{"status":"ok","timestamp":1586443114559,"user_tz":-420,"elapsed":1578,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["data_df['rmstopword_comment'] = [[word for word in list_tokens if is_stopword(word) == False] for list_tokens in data_df['simple_preprocessed_comment']]\n","\n","data_df.head()['rmstopword_comment']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    [absolutely, amazing, first, time, director, k...\n","1        [like, quirky, odd, movies, ironic, fun, one]\n","2    [modern, day, characters, nowhere, near, vivid...\n","3    [metaphor, modern, day, urban, china, searchin...\n","4    [photographic, marvel, sorts, certainly, inval...\n","Name: rmstopword_comment, dtype: object"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"FWxesDv1Xled","colab_type":"text"},"source":["## Stemming"]},{"cell_type":"code","metadata":{"id":"j0WHqVaCXled","colab_type":"code","outputId":"290b5797-8362-4c01-dea2-94dfab24c146","executionInfo":{"status":"ok","timestamp":1586443118227,"user_tz":-420,"elapsed":3713,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["from nltk.stem.porter import PorterStemmer\n","poster = PorterStemmer()\n","\n","data_df['rmstopword_stemming_comment'] = [[poster.stem(word) for word in list_tokens] for list_tokens in data_df['rmstopword_comment']]\n","\n","data_df.head()['rmstopword_stemming_comment']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    [absolut, amaz, first, time, director, kevin, ...\n","1            [like, quirki, odd, movi, iron, fun, one]\n","2    [modern, day, charact, nowher, near, vivid, th...\n","3    [metaphor, modern, day, urban, china, search, ...\n","4    [photograph, marvel, sort, certainli, invalu, ...\n","Name: rmstopword_stemming_comment, dtype: object"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"6jrFhW8b1uo5","colab_type":"code","colab":{}},"source":["X = data_df['rmstopword_comment'].apply(lambda x: ' '.join(x))\n","y = data_df['label']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKVtOgaYXlen","colab_type":"text"},"source":["## CountVectorizer"]},{"cell_type":"code","metadata":{"id":"tvQkyXBnXleo","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vect = CountVectorizer(min_df=2, ngram_range=(1, 1))\n","\n","X_train_count_vect = count_vect.fit(X).transform(X) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y__FxUl2Xlet","colab_type":"code","outputId":"4fd86fdb-2fce-49a2-c12a-244eedf5a987","executionInfo":{"status":"ok","timestamp":1586450936194,"user_tz":-420,"elapsed":814,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# Print score of sentence 0\n","feature_names = count_vect.get_feature_names()\n","\n","feature_index = X_train_count_vect[0,:].nonzero()[1]\n","count_scores = zip(feature_index, [X_train_count_vect[0, x] for x in feature_index])\n","\n","for w, s in [(feature_names[i], s) for (i, s) in count_scores]:\n","    print(w, s)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["absolutely 1\n","action 1\n","add 1\n","amazing 1\n","boring 1\n","canon 1\n","chan 2\n","director 1\n","donovan 1\n","find 1\n","first 1\n","kevin 1\n","make 1\n","managed 1\n","new 1\n","sequences 1\n","something 1\n","time 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x7PJ4oC_Xlew","colab_type":"text"},"source":["## TfidfVectorizer"]},{"cell_type":"code","metadata":{"id":"sRdkVM6TXlew","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tfidf_vect = TfidfVectorizer()\n","X_train_tfidf_vect = tfidf_vect.fit_transform(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXB8yOgIXlez","colab_type":"code","outputId":"078dade4-2577-4532-d865-fe3b44d1dfab","executionInfo":{"status":"ok","timestamp":1586450966752,"user_tz":-420,"elapsed":869,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# Print score of sentence 0\n","feature_names = tfidf_vect.get_feature_names()\n","\n","feature_index = X_train_tfidf_vect[0,:].nonzero()[1]\n","tfidf_scores = zip(feature_index, [X_train_tfidf_vect[0, x] for x in feature_index])\n","\n","for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n","    print(w, s)"],"execution_count":88,"outputs":[{"output_type":"stream","text":["boring 0.20856300210159356\n","sequences 0.2287342850625559\n","action 0.1666146371036295\n","make 0.1550033421234437\n","chan 0.4878690280002895\n","canon 0.2822939450407057\n","add 0.22556250640409523\n","new 0.1642957947128529\n","something 0.16627331628766237\n","find 0.18736268472382375\n","managed 0.2652944407382041\n","donovan 0.27716404351846435\n","kevin 0.24573378936505752\n","director 0.15069603779625476\n","time 0.14558132846228347\n","first 0.1700447235621647\n","amazing 0.2406038878428162\n","absolutely 0.23616016501876405\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nsHjhOcgXle3","colab_type":"text"},"source":["# 73. Training\n","Training model bằng phương pháp logistics regressions sử dụng các đặc trưng tạo ra trong bài 72."]},{"cell_type":"code","metadata":{"id":"-AzAwcr3Ymva","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1R8FCnO-Za6a","colab_type":"text"},"source":["## Train with countvectorize feature"]},{"cell_type":"code","metadata":{"id":"z0H0fHBYY4mz","colab_type":"code","outputId":"bac2d857-35e2-42d7-99b6-41be6b9331d6","executionInfo":{"status":"ok","timestamp":1586451122423,"user_tz":-420,"elapsed":812,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["clf_count = LogisticRegression(random_state=0).fit(X_train_count_vect, y)\n","clf_count.score(X_train_count_vect, y)"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9501969611705121"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"markdown","metadata":{"id":"2RCTRkczZV9v","colab_type":"text"},"source":["## Train with tfidfvectorize feature"]},{"cell_type":"code","metadata":{"id":"kVVaKNuyaL0G","colab_type":"code","outputId":"e2d57d3a-3b49-434c-daa8-a109ffef384f","executionInfo":{"status":"ok","timestamp":1586451135489,"user_tz":-420,"elapsed":1050,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["clf_tfidf = LogisticRegression(random_state=0).fit(X_train_tfidf_vect, y)\n","clf_tfidf.score(X_train_tfidf_vect, y)"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9030200712811856"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"markdown","metadata":{"id":"Dg5SFSqUaWLX","colab_type":"text"},"source":["# 74. Prediction\n","Sử dụng mô hình logistics regressions đã huấn luyện trong bài 73, hãy viết chương trình dự đoán polarity cho một câu đầu vào và tính xác suất cho các nhãn (+1, -1)."]},{"cell_type":"code","metadata":{"id":"FNE1zcYLauel","colab_type":"code","colab":{}},"source":["def predict_sentiment(comment):\n","    \"\"\"\n","    Return the prob of possible labels of the input comment base on cls_tfidf model\n","    \n","    Parameters\n","    ----------\n","    comment : str\n","        The input comment that we want to get label, e.g., `It's so bad`, `It's very good.`\n","    \n","    Returns\n","    -------\n","    out : numpy.ndarray \n","        The prob of possible labels\n","    \"\"\"\n","\n","    # Simple preprocess: remove punctuation, tokenize\n","    comment = simple_preprocess(comment, deacc=True)\n","\n","    # Remove stopword\n","    comment = [word for word in comment if is_stopword(word) == False]\n","\n","    # Convert to feature vector\n","    comment_vect = tfidf_vect.transform(comment)\n","\n","    return clf_tfidf.predict_proba(comment_vect)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSrjW80EboIQ","colab_type":"code","outputId":"c8a267ac-6190-4146-b054-bc395b2d7129","executionInfo":{"status":"ok","timestamp":1586451177206,"user_tz":-420,"elapsed":563,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict_sentiment(\"It's so bad\")\n","# The result shows that the comment's label is 0 --> negative "],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.97353255, 0.02646745]])"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"markdown","metadata":{"id":"ddp-C5FzcFf5","colab_type":"text"},"source":["# 75. Trọng số của các features (Feature weights)\n","Trong mô hình logistics regression đã huấn luyện trong bài 73, đưa ra top 10 các features có trọng số cao nhất và top 10 các features có trọng số thấp nhất."]},{"cell_type":"markdown","metadata":{"id":"SvVZY7LKhEtS","colab_type":"text"},"source":["## Top 10 có trọng số cao nhất"]},{"cell_type":"code","metadata":{"id":"-fvn-MH3dx2a","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoHy_Y1Neda1","colab_type":"code","colab":{}},"source":["top_10_max_indices = np.array(clf_tfidf.coef_[0]).argsort()[-10:][::-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XkwEBTEtgAmv","colab_type":"code","outputId":"30f5cf2a-8a93-4a23-bb3a-a0e3a46d90c5","executionInfo":{"status":"ok","timestamp":1586451186194,"user_tz":-420,"elapsed":1491,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["np.array(tfidf_vect.get_feature_names())[top_10_max_indices]"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['performances', 'entertaining', 'enjoyable', 'best', 'heart',\n","       'still', 'fun', 'powerful', 'solid', 'cinema'], dtype='<U15')"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"markdown","metadata":{"id":"4AlqHSXlgQRM","colab_type":"text"},"source":["## Top 10 có trọng số thấp nhất"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ak6CQfEyhNnu","colab":{}},"source":["top_10_min_indices = np.array(clf_tfidf.coef_[0]).argsort()[:10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"2ce337be-a4d6-45ae-cbbc-d23f3c1c7365","executionInfo":{"status":"ok","timestamp":1586451191520,"user_tz":-420,"elapsed":1238,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"id":"oZc1eaPNhNny","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["np.array(tfidf_vect.get_feature_names())[top_10_min_indices]"],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['bad', 'dull', 'boring', 'worst', 'neither', 'fails', 'feels',\n","       'nothing', 'tv', 'flat'], dtype='<U15')"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"dLtxPSsIhmru","colab_type":"text"},"source":["# 76. Dự đoán trên dữ liệu training\n","Sử dụng mô hình đã học trong bài 73 để đưa ra dự đoán trên dữ liệu training. Đưa ra nhãn gốc, nhãn dự đoán, và xác suất của nhãn dự đoán cho mỗi câu trong dữ liệu (cách nhau bởi ký tự tab)."]},{"cell_type":"code","metadata":{"id":"uFCTaMZqiRs3","colab_type":"code","colab":{}},"source":["predict_labels = clf_tfidf.predict(X_train_tfidf_vect)\n","prob_labels = clf_tfidf.predict_proba(X_train_tfidf_vect)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGckGe--iwJc","colab_type":"code","outputId":"09d14f62-1062-4f74-da8b-488b56f5c38c","executionInfo":{"status":"ok","timestamp":1586451209979,"user_tz":-420,"elapsed":833,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["for l, pl, probl in zip(y[:10], predict_labels[:10], prob_labels[:10]):\n","    print('{}\\t{}\\t{}'.format(l, pl, probl[pl]))"],"execution_count":105,"outputs":[{"output_type":"stream","text":["0\t0\t0.7682821547827502\n","1\t1\t0.6560727381478195\n","0\t1\t0.5458134738264041\n","1\t1\t0.755295543227704\n","1\t1\t0.6925821913525558\n","0\t0\t0.7310788094993885\n","0\t0\t0.6600482753098564\n","1\t1\t0.6051838266322799\n","1\t0\t0.5019497114141189\n","1\t1\t0.7447164543502106\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rHVyUp3EjVDs","colab_type":"text"},"source":["# 77. Tính độ chính xác của mô hình\n","Sử dụng đầu ra của bài 76, tính accuracy cho toàn bộ dữ liệu; precision, recall, F1 cho nhãn +1."]},{"cell_type":"markdown","metadata":{"id":"y6T-GDr8oKMy","colab_type":"text"},"source":["## TP, FP, TN, FN"]},{"cell_type":"code","metadata":{"id":"Wy7fxsDToT1n","colab_type":"code","colab":{}},"source":["TP = 0\n","FP = 0\n","TN = 0\n","FN = 0\n","\n","for l, pl in zip(y, predict_labels):\n","    if pl == 1 and l == 1:\n","        TP += 1\n","    elif pl == 1 and l == 0:\n","        FP += 1\n","    elif pl == 0 and l == 0:\n","        TN += 1\n","    elif pl == 0 and l == 1:\n","        FN += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ayb4Gobrmc2Q","colab_type":"text"},"source":["## Accuracy\n","\n","$$Acc = \\frac{Number\\ of\\ correct\\ predictions}{Number\\ of\\ predictions} = \\frac{TP + TN}{TP + FP + TN + FN}$$"]},{"cell_type":"code","metadata":{"id":"ZVbRtYEqk1EJ","colab_type":"code","outputId":"c443444f-50dc-4e8a-9335-ece9fbbbca6a","executionInfo":{"status":"ok","timestamp":1586451226431,"user_tz":-420,"elapsed":464,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["acc = (TP + TN)/(TP + FP + TN + FN)\n","acc # == clf_tfidf.score(X_train_tfidf_vect, y_train)"],"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9030200712811856"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"vmsGIX4ruPTT","colab_type":"text"},"source":["## Precision"]},{"cell_type":"markdown","metadata":{"id":"KqNCkt6subGq","colab_type":"text"},"source":["$$Precision = \\frac{TP}{TP + FP}$$"]},{"cell_type":"code","metadata":{"id":"RvJZQkA1ubJV","colab_type":"code","outputId":"f091b847-fc62-4bd8-af5e-444e457cf980","executionInfo":{"status":"ok","timestamp":1586451230366,"user_tz":-420,"elapsed":802,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["precision = TP/(TP + FP)\n","precision"],"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9079172204290867"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"markdown","metadata":{"id":"QXxo9uk4u_fk","colab_type":"text"},"source":["## Recall"]},{"cell_type":"markdown","metadata":{"id":"NvnWgMd1vDvK","colab_type":"text"},"source":["$$Recall = \\frac{TP}{TP+FN}$$"]},{"cell_type":"code","metadata":{"id":"LfeB51YmvSuo","colab_type":"code","outputId":"2d8f2022-0a8f-496a-a0a9-82ec47a82e5d","executionInfo":{"status":"ok","timestamp":1586451233035,"user_tz":-420,"elapsed":721,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["recall = TP/(TP + FN)\n","recall"],"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8970174451322454"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"markdown","metadata":{"id":"sf1a3yy4vWEy","colab_type":"text"},"source":["## F1"]},{"cell_type":"markdown","metadata":{"id":"FOYEAbDgvYYZ","colab_type":"text"},"source":["$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$"]},{"cell_type":"code","metadata":{"id":"kdkGNA38vp2D","colab_type":"code","outputId":"1f13db97-4d1b-4828-bfce-529055d61a51","executionInfo":{"status":"ok","timestamp":1586451235794,"user_tz":-420,"elapsed":710,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["f1 = (2 * precision * recall)/(precision + recall)\n","f1"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9024344215889791"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"VxO-qJh7wGux","colab_type":"text"},"source":["# 78. 5-fold cross validation\n","Vì các thực nghiệm trong bài 76, 77 đánh giá model trên dữ liệu huấn luyện nên khó có thể nói đó là các đánh giá hợp lý. Các đánh giá này chỉ đánh giá khả năng mô hình \"fit\" với dữ liệu training chứ không đánh giá khả năng khái quát (generalization) của mô hình. Vì thế bài tập 78 yêu cầu bạn đánh giá mô hình sử dụng 5-fold cross validation. Đưa ra accuracy, precision, recall, F1 score cho 5-fold cross validation (tính trung bình của 5 folds)."]},{"cell_type":"code","metadata":{"id":"-TRoIF0eyaSx","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold\n","kf = KFold(n_splits=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdgqc1Cj4jza","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"d78fe425-ccf6-48b4-919c-2622e5c76ab1","executionInfo":{"status":"ok","timestamp":1586452756638,"user_tz":-420,"elapsed":1848,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}}},"source":["metric_dict = {'acc_avg': 0, 'precision_avg': 0, 'recall_avg': 0, 'f1_avg': 0}\n","\n","for train_index, test_index in kf.split(X_train_tfidf_vect):\n","    X_train_kfold, X_test_kfold = X_train_tfidf_vect[train_index], X_train_tfidf_vect[test_index]\n","    y_train_kfold, y_test_kfold = y[train_index], y[test_index]\n","\n","    clf_tfidf_kfold = LogisticRegression(random_state=0).fit(X_train_kfold, y_train_kfold)\n","\n","    predict_labels_kfold = clf_tfidf.predict(X_test_kfold)\n","\n","    # Calc TP, FP, TN, FN\n","    TP, FP, TN, FN = 0, 0, 0, 0\n","\n","    for l, pl in zip(y_test_kfold, predict_labels_kfold):\n","        if pl == 1 and l == 1:\n","            TP += 1\n","        elif pl == 1 and l == 0:\n","            FP += 1\n","        elif pl == 0 and l == 0:\n","            TN += 1\n","        elif pl == 0 and l == 1:\n","            FN += 1\n","\n","    metric_dict['acc_avg'] += ((TP + TN)/(TP + FP + TN + FN))/5\n","\n","    precision = TP/(TP + FP)\n","    metric_dict['precision_avg'] += precision/5\n","\n","    recall = TP/(TP + FN)\n","    metric_dict['recall_avg'] += recall/5\n","\n","    metric_dict['f1_avg'] += ((2 * precision * recall)/(precision + recall))/5\n","\n","\n","print('Average accuracy of 5-fold', metric_dict['acc_avg'])\n","print('Average precision of 5-fold', metric_dict['precision_avg'])\n","print('Average recall of 5-fold', metric_dict['recall_avg'])\n","print('Average F1 of 5-fold', metric_dict['f1_avg'])"],"execution_count":116,"outputs":[{"output_type":"stream","text":["Average accuracy of 5-fold 0.9030190722225301\n","Average precision of 5-fold 0.9081078846024377\n","Average recall of 5-fold 0.8970179457435152\n","Average F1 of 5-fold 0.9025116534522175\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8AT0wOld79h8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}