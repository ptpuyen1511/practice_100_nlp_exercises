{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"c9_vector_space_1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"U-qxYMts_hqN","colab_type":"text"},"source":["# Chương 9: Không gian vector (I)\n","File enwiki-20150112-400-r10-105752.txt.bz2 là file nén dạng bzip2 của 105752 file text được lấy mẫu ngẫu nhiên (tỷ lệ 1/10) từ các bài báo trên Wikipedia có trên 400 từ. Các bài báo trên Wikipedia được lấy vào ngày 12 tháng 1 năm 2015. Sử dụng dữ liệu file này làm corpus để học các vector thể hiện ý nghĩa của các từ. Trong nửa đầu của chương 9, bạn được yêu cầu trích xuất các context của các từ, trích xuất đặc trưng, và dùng phương pháp PCA để giảm bớt số chiều của dữ liệu. Nửa sau của chương 9 yêu cầu bạn tính độ tương tự của các từ sử dụng các word vectors đã học từ corpus.\n","\n","Chú ý, bài 83 yêu cầu 7GB memory. Trong trường hợp lượng memory của bạn không đủ, bạn cần có các phương pháp xử lý thích hợp hoặc sử dụng sample 1/100 của dữ liệu trong file enwiki-20150112-400-r10-105752.txt.bz2."]},{"cell_type":"markdown","metadata":{"id":"2hVQS_bg_rYa","colab_type":"text"},"source":["# Download data"]},{"cell_type":"code","metadata":{"id":"6of0_egR_hqO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"baf99533-31ee-46a8-d45c-752fbc9d72dc","executionInfo":{"status":"ok","timestamp":1587225327890,"user_tz":-420,"elapsed":21998,"user":{"displayName":"Uyên Phan Thị Phương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiijKAhyj7aP8xr8kcdLaOI4T7SSx6ouaFX6-w4gQ=s64","userId":"07106054718633244101"}}},"source":["!wget http://www.cl.ecei.tohoku.ac.jp/nlp100/data/enwiki-20150112-400-r10-105752.txt.bz2"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-04-18 15:55:04--  http://www.cl.ecei.tohoku.ac.jp/nlp100/data/enwiki-20150112-400-r10-105752.txt.bz2\n","Resolving www.cl.ecei.tohoku.ac.jp (www.cl.ecei.tohoku.ac.jp)... 130.34.192.83\n","Connecting to www.cl.ecei.tohoku.ac.jp (www.cl.ecei.tohoku.ac.jp)|130.34.192.83|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 221903910 (212M) [application/x-bzip2]\n","Saving to: ‘enwiki-20150112-400-r10-105752.txt.bz2’\n","\n","enwiki-20150112-400 100%[===================>] 211.62M  11.2MB/s    in 19s     \n","\n","2020-04-18 15:55:24 (11.1 MB/s) - ‘enwiki-20150112-400-r10-105752.txt.bz2’ saved [221903910/221903910]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45oxjqJ0BHpG","colab_type":"code","colab":{}},"source":["!bzip2 -d enwiki-20150112-400-r10-105752.txt.bz2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPN11Ill__R2","colab_type":"text"},"source":["# 80. Tiền xử lý dữ liệu\n","Sử dụng khoảng trắng là ký tự ngăn cách để tokenize các từ trong các câu. Phương pháp này có nhược điểm là các từ thu được sẽ còn các ký tự đặc biệt như dấu câu, hoặc dấu ngoặc. Vì thế sau khi tokenize các từ trong corpus, tiến hành các xử lý sau đây.\n","\n","* Xoá các ký tự đặc biệt xuất hiện ở đầu và cuối các từ: .,!?;:()[]'\"\n","* Xoá các từ chỉ gồm ký tự trắng\n","Sau khi tiền xử lý dữ liệu, lưu file dữ liệu gồm danh sách các từ cách nhau bởi khoảng trắng."]},{"cell_type":"code","metadata":{"id":"P_AhxzOoASn7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}